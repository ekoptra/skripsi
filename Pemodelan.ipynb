{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemodelan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas_datareader\n",
    "# ! pip install ta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import datetime as dt\n",
    "import ta\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_sentiment(compound, threshold_neg=-0.05, threshold_pos=0.05):\n",
    "    if compound is None : return  None\n",
    "    if compound < threshold_neg : return \"Negative\"\n",
    "    if compound > threshold_pos : return \"Positive\"\n",
    "    return \"Netral\"\n",
    "\n",
    "all_articles = pd.read_json('data/data_vader.json')\n",
    "saham = pd.read_json('data/table_saham.json')\n",
    "article_saham = pd.read_json(\"data/table_article_saham.json\")\n",
    "\n",
    "all_articles['sentiment_category'] = all_articles.mean_compound.apply(category_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Saham Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSaham():\n",
    "    \"\"\"\n",
    "    This class is for constructing all the required variables. \n",
    "    There are 11 technical Indicators, sentiment score & category\n",
    "    and Rupiah/USD exchange rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, code, all_articles, saham, article_saham, start_date=\"2000-01-01\", end_date=None, window=10, dropna=False):\n",
    "        self.code = code\n",
    "        self.full_data = self.__scraping_saham(start_date, end_date)\n",
    "        self.__get_technical_indicators(window)\n",
    "        if dropna:\n",
    "            self.full_data = self.full_data.dropna()\n",
    "            \n",
    "        self.articles = self.__get_articles(all_articles, saham, article_saham)\n",
    "        self.__get_sentiment_score()\n",
    "        self.__get_sentiment_category()\n",
    "        self.__get_kurs_rupiah()\n",
    "        \n",
    "    @property\n",
    "    def data(self):\n",
    "        selected_variabel = ['close', 'sma', 'wma', 'macd', 'cci', '%k', '%d', \n",
    "                             'rsi', 'williams_r', 'a/d', 'momentum',\n",
    "                             'sentiment_score', 'price']\n",
    "        \n",
    "        return self.full_data[selected_variabel]\n",
    "\n",
    "        \n",
    "    def __get_articles(self, all_articles, saham, article_saham):\n",
    "        saham_id = saham.loc[saham.code == self.code, \"id\"].to_list()[0]\n",
    "        selected_article = article_saham[article_saham.saham_id == saham_id]\n",
    "\n",
    "        articles = all_articles[all_articles.id.isin(selected_article.article_id.to_list())]\n",
    "        articles.loc[ :, 'date'] = articles.loc[:, 'published_at'].dt.strftime(\"%Y-%m-%d\")\n",
    "        return articles\n",
    "            \n",
    "    def __scraping_saham(self, start_date=\"2000-01-01\", end_date=None):\n",
    "        start_date = dt.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end_date = dt.datetime.now() if end_date is None else dt.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    \n",
    "        data = (pdr.get_data_yahoo(self.code + '.JK', start_date, end_date)\n",
    "                .rename(columns={\"Adj Close\" : \"adj_close\"})\n",
    "                .rename_axis('date')\n",
    "                .reset_index())\n",
    "        \n",
    "        data.columns = data.columns.str.lower()\n",
    "        data.loc[:, \"date\"] = data.date.astype(str)\n",
    "        return data.set_index('date')\n",
    "    \n",
    "    def __momentum(self, close, window=10):\n",
    "        def calculate(x):\n",
    "            x = x.to_list()\n",
    "            return x[window] - x[0]\n",
    "        \n",
    "        return close.rolling(window + 1).apply(calculate)\n",
    "\n",
    "    def __acc_dist_oscilator(self, high, low, close):\n",
    "        return (high - close.shift(1)) / (high - low)\n",
    "    \n",
    "    def __get_technical_indicators(self, window=10):\n",
    "        self.full_data['sma'] = ta.trend.sma_indicator(self.full_data.close, window=window)\n",
    "        self.full_data['wma'] = ta.trend.wma_indicator(self.full_data.close, window=window)\n",
    "        self.full_data['macd'] = ta.trend.macd(self.full_data.close)\n",
    "        self.full_data['cci'] = ta.trend.cci(self.full_data.high, self.full_data.low, self.full_data.close)\n",
    "        self.full_data['%k'] = ta.momentum.stoch(self.full_data.high, self.full_data.low, self.full_data.close)\n",
    "        self.full_data['%d'] = ta.momentum.stoch_signal(self.full_data.high, self.full_data.low, self.full_data.close)\n",
    "        self.full_data['rsi'] = ta.momentum.rsi(self.full_data.close)\n",
    "        self.full_data['williams_r'] = ta.momentum.williams_r(self.full_data.high, self.full_data.low, self.full_data.close)\n",
    "        self.full_data['mfi'] = ta.volume.money_flow_index(self.full_data.high, self.full_data.low, self.full_data.close, self.full_data.volume)\n",
    "        self.full_data['momentum'] = self.__momentum(self.full_data.close, window=window)\n",
    "        self.full_data['a/d'] = self.__acc_dist_oscilator(self.full_data.high, self.full_data.low, self.full_data.close)\n",
    "        \n",
    "    def __get_sentiment_score(self):        \n",
    "        sentiment_article = (self.articles\n",
    "                        .groupby('date')['mean_compound']\n",
    "                        .mean()\n",
    "                        .to_frame()\n",
    "                        .reset_index()\n",
    "                        .rename(columns={\"mean_compound\" : \"sentiment\"}))\n",
    "        \n",
    "        new_df = self.full_data[['close']].copy().reset_index()\n",
    "        new_df['date'] = new_df.date.astype(str)\n",
    "        sentiment_close = (pd.merge(new_df, sentiment_article, on='date', how='outer')\n",
    "                    .sort_values(\"date\")\n",
    "                    .reset_index(drop=True))\n",
    "        sentiment_close['sentiment'] = sentiment_close.sentiment.fillna(0)\n",
    "\n",
    "        # where the close price is null, meaning that there is no trading on that day\n",
    "        # so the sentiment on that day will be averaged over the next trading day\n",
    "        close_null = sentiment_close[sentiment_close.close.isnull()].index.to_list()\n",
    "        index_close_null = 0\n",
    "        index_curr = -1\n",
    "        sentiment = 0\n",
    "        count_consecutive_day = 0\n",
    "\n",
    "        while index_close_null <= len(close_null) - 1:\n",
    "            \n",
    "            # first day without trading\n",
    "            index_curr = close_null[index_close_null]\n",
    "            sentiment = sentiment_close.sentiment[index_curr]\n",
    "            count_consecutive_day = 1\n",
    "            index_curr += 1\n",
    "            \n",
    "            # where index curr not in close null, meaning there are\n",
    "            # trading on that day\n",
    "            while index_curr in close_null:\n",
    "                sentiment += sentiment_close.sentiment[index_curr]\n",
    "                count_consecutive_day += 1\n",
    "                index_curr += 1\n",
    "                index_close_null += 1\n",
    "            \n",
    "            try:\n",
    "                if sentiment_close.sentiment[index_curr] != 0: \n",
    "                    sentiment += sentiment_close.sentiment[index_curr]\n",
    "                    count_consecutive_day += 1\n",
    "                    \n",
    "                sentiment_close.loc[index_curr, \"sentiment\"] = sentiment / count_consecutive_day\n",
    "            except:\n",
    "                pass\n",
    "            finally:\n",
    "                index_close_null += 1\n",
    "               \n",
    "        sentiment_close = (sentiment_close[sentiment_close.close.notnull()]\n",
    "                            .set_index('date')[['sentiment']]\n",
    "                            .rename(columns={'sentiment' : 'sentiment_score'})) \n",
    "        \n",
    "        self.full_data = self.full_data.join(sentiment_close).fillna(0)\n",
    "        \n",
    "    def __get_sentiment_category(self):\n",
    "        sentiment_category = (self.articles\n",
    "                              .groupby(['date', 'sentiment_category'])['sentiment_category']\n",
    "                              .count()\n",
    "                              .to_frame()\n",
    "                              .rename(columns={\"sentiment_category\" : 'jumlah'})\n",
    "                              .reset_index()\n",
    "                              .pivot(index='date', columns='sentiment_category', values='jumlah')\n",
    "                              .fillna(0)\n",
    "                              .reset_index()\n",
    "                              .rename_axis(None, axis=1))\n",
    "        sentiment_category.columns = sentiment_category.columns.str.lower()\n",
    "        \n",
    "        df = self.full_data[['close']].copy().reset_index()\n",
    "        df = (pd.merge(df, sentiment_category, on='date', how='outer')\n",
    "                        .sort_values(\"date\")\n",
    "                        .reset_index(drop=True))\n",
    "        \n",
    "        df.negative = df.negative.fillna(0)\n",
    "        df.positive = df.positive.fillna(0)\n",
    "        df.netral = df.netral.fillna(0)\n",
    "    \n",
    "        # where the close price is null, meaning that there is no trading on that day\n",
    "        # so the sentiment on that day will be averaged over the next trading day\n",
    "        close_null = df[df.close.isnull()].index.to_list()\n",
    "        index_close_null = 0\n",
    "        index_curr = -1\n",
    "        pos = net = neg = 0\n",
    "\n",
    "        while index_close_null <= len(close_null) - 1:            \n",
    "            # first day without trading\n",
    "            index_curr = close_null[index_close_null]\n",
    "            pos = df.positive[index_curr]    \n",
    "            neg = df.negative[index_curr]\n",
    "            net = df.netral[index_curr]\n",
    "            index_curr += 1\n",
    "            \n",
    "            # where index curr not in close null, meaning there are\n",
    "            # trading on that day\n",
    "            while index_curr in close_null:\n",
    "                pos += df.positive[index_curr]    \n",
    "                neg += df.negative[index_curr]\n",
    "                net += df.netral[index_curr]\n",
    "                index_curr += 1\n",
    "                index_close_null += 1\n",
    "            \n",
    "            try:            \n",
    "                df.loc[index_curr, \"positive\"] += pos \n",
    "                df.loc[index_curr, \"negative\"] += neg\n",
    "                df.loc[index_curr, \"netral\"] += net\n",
    "            except:\n",
    "                pass\n",
    "            finally:\n",
    "                index_close_null += 1\n",
    "                \n",
    "        df = df[df.close.notnull()].set_index('date').drop('close', axis=1)\n",
    "        self.full_data = self.full_data.join(df).fillna(0)\n",
    "        self.full_data['sentiment_category_score'] = (self.full_data.positive - self.full_data.negative) / (self.full_data.positive + self.full_data.negative + 1)\n",
    "        \n",
    "    def __get_kurs_rupiah(self):\n",
    "        kurs = (pd.read_csv('data/kurs.csv')\n",
    "                    .loc[:, [\"Date\", \"Price\"]]\n",
    "                    .rename(columns={\"Date\" : \"date\", \"Price\" : \"price\"}))\n",
    "\n",
    "        kurs['date'] = pd.to_datetime(kurs.date).astype(str)\n",
    "        kurs = kurs.set_index('date')\n",
    "        self.full_data = self.full_data.join(kurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "bri = DataSaham('BBRI', all_articles, saham, article_saham, end_date=\"2021-12-31\", dropna=True)\n",
    "bri.data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "380030d1298d5a27518acca789ff38fe82bbf2e68b73263de6a6bf23efb7704c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
